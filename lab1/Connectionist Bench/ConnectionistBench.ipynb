{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9A5ZXHw9DcD"
   },
   "source": [
    "Από την Ομάδα 70, που αποτελείται από τους:\n",
    "* Ιωάννης Μιχαήλ Καζελίδης 03117885\n",
    "* Μάριος Κερασιώτης 03117890\n",
    "* Ιωάννης Γκιορτζής 03117152\n",
    "\n",
    "Στην ομάδα μας αντιστοιχούν τα εξής datasets:\n",
    "* U09: Connectionist Bench (Sonar, Mines vs. Rocks)\n",
    "* K02: Company Bankruptcy Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QdZUl_o9DcH"
   },
   "source": [
    "# UCI: Connectionist Bench (Sonar, Mines vs. Rocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D39p5MJVmbW4"
   },
   "outputs": [],
   "source": [
    "# !pip3 install -q -U pip matplotlib numpy pandas seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYVp1I9TwwwJ"
   },
   "outputs": [],
   "source": [
    "DATASET_URI = 'https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data'\n",
    "PICKLE_FILE = 'sonar.all-data.df'\n",
    "\n",
    "import os.path\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tabulate\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from IPython.display import HTML, display\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest,\n",
    "    SelectPercentile,\n",
    "    VarianceThreshold,\n",
    "    chi2,\n",
    "    f_classif,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer, RobustScaler, StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid', palette=\"cubehelix\")\n",
    "sns.set(rc={'figure.figsize': (20, 15)})\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eLX-zaxFJ3Q"
   },
   "source": [
    "## Εισαγωγή και επισκόπηση"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGTS_i8H9DcK"
   },
   "source": [
    "### Διερεύνηση του Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "Lo1Ep8bcmuzV",
    "outputId": "5965e832-4ced-4346-fcf0-cbc4daf21d13"
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(PICKLE_FILE):\n",
    "    with open(PICKLE_FILE, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "else:\n",
    "    column_headers = [\"T{}\".format(str(i)) for i in range(60)]\n",
    "    column_headers.append(\"Object\")\n",
    "    data = pd.read_csv(DATASET_URI, names=column_headers)\n",
    "\n",
    "    with open(PICKLE_FILE, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63gnWEudble_",
    "outputId": "827fa6d5-1c92-48f8-f3a5-65743f70d0ea"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_N-UvNi69DcM"
   },
   "outputs": [],
   "source": [
    "features = data[data.columns.drop('Object')]\n",
    "labels = data['Object'].astype('category')\n",
    "del (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6TjAO-tXpLIj",
    "outputId": "70168ac2-91eb-4d8e-e0b2-392fb98b5b90"
   },
   "outputs": [],
   "source": [
    "print(\"Dimensions of features:\", features.shape)\n",
    "print(\"Dimensions of labels:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rIIhYWNmblfB",
    "outputId": "0b34e383-20d7-4f70-b2d6-3a7a9b11e986"
   },
   "outputs": [],
   "source": [
    "print('Unique labels', np.unique(labels))\n",
    "labels.value_counts() / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "vrFNPmLc1C7N",
    "outputId": "8042ff25-a054-42f3-a4b7-8dbdbde7344a"
   },
   "outputs": [],
   "source": [
    "features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 913
    },
    "id": "7gA-Wx109DcN",
    "outputId": "931b7248-9562-4309-a9ad-fcec44eed779"
   },
   "outputs": [],
   "source": [
    "boxplot = sns.boxplot(data=features)\n",
    "boxplot.set(title='Boxplot of dataset features',\n",
    "            xlabel='Column',\n",
    "            ylabel='Value')\n",
    "sns.despine(offset=2)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "id": "Vk7PLcZe9DcO",
    "outputId": "a5a253fe-50d7-4b2d-c358-ca295ae68512"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(features.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVGD9z3U9DcO"
   },
   "source": [
    "### Απάντηση στα ζητούμενα"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCkru9ylrBCM"
   },
   "source": [
    "1. Σύντομη Παρουσίαση Dataset και Περιγραφή Προβλήματος\n",
    "     - Το γενικό πρόβλημα αποτελεί την κατηγοριοποίηση διαφόρων σημάτων με την βοήθεια ενός ταξινομητή. Ένα σύστημα SO.N.A.R. εκπέμπει σήματα, για τα οποία καλούμαστε να διακρίνουμε αν η επιφάνεια στην οποία ανακλώνται είναι μέταλλο ή πέτρα.\n",
    "\n",
    "     - Το συγκεκριμένο dataset είναι ένα σύνολο μοτίβων από σήματα που λήφθηκαν από μεταλλικούς και πέτρινους κυλίνδρους. Κάθε γραμμή αποτελεί είτε έναν μεταλλικό είτε ένα πέτρινο κύλινδρο και οι μετρήσεις κατά μήκος της γραμμής είναι οι διάφορες ενέργειες των σημάτων σε διαφορετικές γωνίες και καταστάσεις του. Κάθε γραμμή περιέχει 60 μετρήσεις, καθώς και τον τύπο του κυλίνδρου στην 61η στήλη. Συνολικά υπάρχουν 208 τέτοιες γραμμές από τα διάφορα υλικά.  \n",
    "\n",
    "2. Χρειάστηκε να κάνετε μετατροπές στα αρχεία plain text για την εισαγωγή του; αν ναι, ποιες είναι αυτές;\n",
    "   - Δεν χρειάστηκε κάποια μετατροπή στα δεδομένα εκτός από το να διαβάζουμε το αρχείο σε μορφή csv (με την επιλογή να μην έχει το dataset κεφαλίδες).\n",
    "\n",
    "3. Δώστε το πλήθος δειγμάτων και χαρακτηριστικών, και το είδος όλων των χαρακτηριστικών. Υπάρχουν μη διατεταγμένα χαρακτηριστικά και ποια είναι αυτά;\n",
    "    - Συνολικά έχουμε 208 δείγματα. Από αυτά, τα 111 είναι μοτίβα τα οποία λαμβάνουμε από τους μεταλλικούς κυλίνδρους σε διαφορετικές γωνίες και καταστάσεις, ενώ τα 97 είναι μοτίβα τα οποία λαμβάνουμε από τις κυλινδρικές πέτρες κάτω από αντίστοιχες συνθήκες. Επίσης, για κάθε ένα από αυτά τα δείγματα, έχουμε 60 μετρήσεις, οι οποίες αναφέρονται σε ενέργεια, της οποίας η τιμή κυμαίνεται κάθε φορά από 0.0 έως 1.0 (στο dataset αυτές αναπαριστώνται ως float64), καθώς και ένα αναγνωριστικό που δείχνει την κλάση στην οποία ανήκει το δείγμα, με M για μέταλλο και R για πέτρα (στο dataset αυτό αναπαριστάται ως object). Αυτά τα \"αναγνωριστικά\" είναι και τα χαρακτηριστικά τα οποία είναι μη διατεταγμένα, εφόσον δεν είναι αριθμητικά, και έτσι δεν μπορούμε να τα διατάξουμε με κάποιο τρόπο.\n",
    "\n",
    "4. Υπάρχουν επικεφαλίδες; Αρίθμηση γραμμών;\n",
    "    - Το αρχείο αποτελείται μόνο από τα δεδομένα διαχωρισμένα με το σύμβολο `,` και δεν περιέχει ούτε κεφαλίδες ούτε αρίθμηση γραμμών. Κεφαλίδες προσθέσαμε εμείς ύστερα στο dataframe.\n",
    "\n",
    "5. Ποιες είναι οι ετικέτες των κλάσεων και σε ποια κολόνα βρίσκονται;\n",
    "    - Οι ετικέτες βρίσκονται στην στήλη 61 και έχουν τις τιμές `R` και `Μ` για πέτρα ή μέταλλο αντίστοιχα.\n",
    "\n",
    "6. Υπάρχουν απουσιάζουσες τιμές; Πόσα είναι τα δείγματα με απουσιάζουσες τιμές και ποιο το ποσοστό τους επί του συνόλου;\n",
    "    - Κάθε γραμμή έχει 60 μετρήσεις και ένα αναγνωριστικό που δείχνει την κλάση στην οποία ανήκει και έτσι δεν έχουμε απουσιάζουσες τιμές για κανένα από τα δείγματα (όπως φαίνεται και παραπάνω από τον κώδικα). Έτσι το ποσοστό των δειγμάτων με απουσιάζουσες τιμές είναι `0%`.\n",
    "\n",
    "7. Ποιο είναι το πλήθος των κλάσεων και τα ποσοστά δειγμάτων τους επί του συνόλου; Αν θεωρήσουμε ότι ένα dataset είναι μη ισορροπημένο αν μια οποιαδήποτε κλάση είναι 1.5 φορά πιο συχνή από κάποια άλλη (60%-40% σε binary datasets) εκτιμήστε αν το dataset είναι ισορροπημένο ή όχι.\n",
    "    - Το πλήθος των κλάσεων είναι 2, μεταλλικοί κύλινδροι και κυλινδρικές πέτρες. Τα ποσοστά δειγμάτων τους επί του συνόλου είναι αντίστοιχα #Μ = 111, και άρα `53.37%` και #R = 97 και άρα `46.63%`. Καμία κλάση δεν είναι 1.5 φορά πιο συχνή από κάποια άλλη, και συνεπώς το dataset είναι ισορροπημένο."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PetPgVDFew0"
   },
   "source": [
    "## Προετοιμασία"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYVDwQ2u9DcP"
   },
   "source": [
    "### Διαχείριση κατηγορικών δεδομένων"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zpa6mymFcfDN"
   },
   "source": [
    "Καταρχάς, διαχωρίζουμε το σύνολο δεδομένων σε σύνολο εκπαίδευσης (train set) και σύνολο (test set) με 30% των δειγμάτων στο test set και στην συνέχεια θα κάνουμε διαχείριση κατηγορικών δεδομένων, όπως φαίνεται παρακάτω."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6UjXFB0o4bE"
   },
   "outputs": [],
   "source": [
    "train, test, train_labels, test_labels = train_test_split(features,\n",
    "                                                          labels,\n",
    "                                                          test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qs-S-LSl9DcQ",
    "outputId": "e82f7d40-4bc7-47f9-93ac-abbbe8fd9a99"
   },
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2o7d-cB1ZRe"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "# we are fitting the Label Encoder with train_labels\n",
    "# to avoid data leakage\n",
    "le.fit(train_labels)\n",
    "train_labels = pd.Series(le.transform(train_labels),\n",
    "                         name='Object').astype('category')\n",
    "test_labels = pd.Series(le.transform(test_labels),\n",
    "                        name='Object').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bai9PNVx9DcQ",
    "outputId": "395ae5b3-e18b-48c4-eab5-4b965fbb26fc"
   },
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8aGpnoVd1ZRh"
   },
   "source": [
    "Όπως φαίνεται και παραπάνω, το κατηγορικό (και μη διατεταγμένο) χαρακτηριστικό που διέκρινε τα δείγματα σε R και M, μέσω του label encoder τα αντιστοιχήσαμε σε 1 και 0 αντίστοιχα, για να είναι πιο εύκολη η επεξεργασία και η διαχείριση των δεδομένων μας και να είναι αποδοτικότερο το πρόγραμμά μας."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jx5YZ6Wo9DcR"
   },
   "source": [
    "### Διαχείριση απουσιάζουσων τιμών"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TNFudu99DcR"
   },
   "source": [
    "Τα δεδομένα δεν έχουν απουσιάζουσες τιμές και έτσι δεν χρειάζεται κάποια περαιτέρω προετοιμασία του dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oztTyJFI1ZRh"
   },
   "source": [
    "## Ταξινόμηση"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpT5I9IOI7-O"
   },
   "source": [
    "Αρχικά θα δούμε πώς συμπεριφέρονται οι ταξινομητές χωρίς καμία βελτιστοποίηση (out-of-the-box) και με όλες τις παραμέτρους σε default τιμές."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d58dUFc91ZRi"
   },
   "outputs": [],
   "source": [
    "out_of_the_box_scores = pd.DataFrame()\n",
    "\n",
    "\n",
    "def add_scores(metric, classifier, score):\n",
    "    global out_of_the_box_scores\n",
    "    out_of_the_box_scores = out_of_the_box_scores.append(\n",
    "        {\n",
    "            'Metric': metric,\n",
    "            'Classifier': classifier,\n",
    "            'Score': score\n",
    "        },\n",
    "        ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eA26g9fqeh77"
   },
   "source": [
    "### Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmicLzuw1ZRi"
   },
   "outputs": [],
   "source": [
    "dc = DummyClassifier()\n",
    "dc.fit(train, train_labels)\n",
    "preds = dc.predict(test)\n",
    "\n",
    "score_acc = accuracy_score(test_labels, preds)\n",
    "score_f1 = f1_score(test_labels, preds)\n",
    "\n",
    "add_scores('Accuracy', 'Dummy', score_acc)\n",
    "add_scores('F1', 'Dummy', score_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjnYNgJlen6M"
   },
   "source": [
    "### Gaussian Naive Bayes (GNB) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRR-xu9u1ZRj"
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(train, train_labels)\n",
    "preds = gnb.predict(test)\n",
    "\n",
    "score_acc = accuracy_score(test_labels, preds)\n",
    "score_f1 = f1_score(test_labels, preds)\n",
    "\n",
    "add_scores('Accuracy', 'Gaussian Naive Bayes', score_acc)\n",
    "add_scores('F1', 'Gaussian Naive Bayes', score_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-5ck10OeqDp"
   },
   "source": [
    "### KNeirestNeighbors (kNN) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PhxrLKJC5N1w"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(train, train_labels)\n",
    "preds = knn.predict(test)\n",
    "\n",
    "score_acc = accuracy_score(test_labels, preds)\n",
    "score_f1 = f1_score(test_labels, preds)\n",
    "\n",
    "add_scores('Accuracy', 'K-nearest neighbors', score_acc)\n",
    "add_scores('F1', 'K-nearest neighbors', score_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZUrHSZ2esjY"
   },
   "source": [
    "### Logistic Regression (LR) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rzdFGouh5kQ3"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train, train_labels)\n",
    "preds = lr.predict(test)\n",
    "\n",
    "score_acc = accuracy_score(test_labels, preds)\n",
    "score_f1 = f1_score(test_labels, preds)\n",
    "\n",
    "add_scores('Accuracy', 'Logistic Regression', score_acc)\n",
    "add_scores('F1', 'Logistic Regression', score_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lP4hWJvKe2zD"
   },
   "source": [
    "### Παρουσίαση επίδοσης out-of-the-box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "a1KhQ9-E9DcT",
    "outputId": "2c022fc6-6210-453c-e234-b430c434f1dc"
   },
   "outputs": [],
   "source": [
    "out_of_the_box_scores.groupby('Classifier').apply(\n",
    "    lambda a: a.drop('Classifier', axis=1)[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 899
    },
    "id": "8DPMB7AH-wEd",
    "outputId": "050f9f14-dc51-4ed9-c0f6-afd1f78acc12"
   },
   "outputs": [],
   "source": [
    "barplot = sns.barplot(data=out_of_the_box_scores,\n",
    "                      y='Score',\n",
    "                      x='Classifier',\n",
    "                      hue='Metric')\n",
    "barplot.set(title='Accuracy and F1 scores for out of the box classifiers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRq7Gk7HEmeC"
   },
   "source": [
    "Παραπάνω βλέπουμε την συμπεριφορά των ταξινομητών χωρίς καμία βελτιστοποίηση (out-of-the-box) και με όλες τις παραμέτρους σε default τιμές. Παρατηρούμε πως και για τις 2 μετρικές, οι επιδόσεις βελτιώνονται όσο περνάμε από τον Dummy στον Gaussian, και από τον Gaussian στον kNN, όπου και εμφανίζονται οι μεγαλύτερες επιδόσεις. Παρόλο που από τον kNN στον LR παρουσιάζεται μια πτώση και στις 2 μετρικές, η επίδοση του LR είναι καλύτερη στις 2 μετρικές και από τον Dummy αλλά και από τον Gaussian ταξινομητή. Αυτό σημαίνει πως χωρίς καμία βελτιστοποίηση κυρίως οι ταξινομητές kNN και LR εμφανίζουν την καλύτερη επίδοση στις υπό εξέταση μετρικές (με εμφανώς καλύτερη επίδοση στον kNN), ενώ ο Dummy παρουσιάζει την χαμηλότερη."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZP0VRR37HJkj"
   },
   "source": [
    "## Βελτιστοποίηση"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-D5m4CuCqnsO"
   },
   "source": [
    "### Ανάλυση Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQ3RwaNyRV0q"
   },
   "source": [
    "Με βάση το boxplot που φαίνεται παραπάνω παρατηρούμε πως θα βοηθούσε να κανονικοποιήσουμε τα δεδομένα μας. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 908
    },
    "id": "F9sEEKplOB47",
    "outputId": "9f83f77c-5deb-4584-fea8-5628d5495926"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "scaler.fit_transform(features)\n",
    "robust_scaler.fit_transform(features)\n",
    "\n",
    "scaled_features = pd.DataFrame(scaler.fit_transform(features),\n",
    "                               columns=features.columns)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "sns.boxplot(data=scaled_features, ax=ax[0]).set(title='Standard Scaler',\n",
    "                                                xlabel='Column',\n",
    "                                                ylabel='Value')\n",
    "sns.despine(offset=2)\n",
    "plt.xticks(rotation=45)\n",
    "sns.boxplot(data=robust_scaler.fit_transform(features),\n",
    "            ax=ax[1]).set(title='Robust Scaler',\n",
    "                          xlabel='Column',\n",
    "                          ylabel='Value')\n",
    "sns.despine(offset=2)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEEzqhVZSZaL"
   },
   "source": [
    "Πράγματι, με την χρήση των Scaler φαίνεται ότι τα δεδομένα κανονικοποιήθηκαν, οπότε μπορούμε να τους χρησιμοποιήσουμε στην προσπάθεια βελτίωσης των επιδόσεων των ταξινομητών."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2Mrusneqnsa"
   },
   "source": [
    "### Βοηθητικές συναρτήσεις"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eco19e5Iqnsb"
   },
   "outputs": [],
   "source": [
    "preprocessing_scores = pd.DataFrame()\n",
    "\n",
    "\n",
    "def train_best_model(cv_classifier, classifier, scoring_metric):\n",
    "    global preprocessing_scores\n",
    "    out_of_the_box_score = lambda m: out_of_the_box_scores.loc[\n",
    "        (out_of_the_box_scores['Classifier'] == classifier) &\n",
    "        (out_of_the_box_scores['Metric'] == m)]['Score'].values[0]\n",
    "    pipe = cv_classifier.best_estimator_\n",
    "\n",
    "    start_time = time.time()\n",
    "    pipe.fit(train, train_labels)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    preds = pipe.predict(test)\n",
    "    test_time = time.time() - start_time\n",
    "\n",
    "    score_acc = accuracy_score(test_labels, preds)\n",
    "    score_f1 = f1_score(test_labels, preds)\n",
    "\n",
    "    preprocessing_scores = preprocessing_scores.append(\n",
    "        {\n",
    "            \"Classifier\": classifier,\n",
    "            \"Scoring_metric\": scoring_metric,\n",
    "            \"Accuracy\": score_acc,\n",
    "            \"ΔAccuracy\": score_acc - out_of_the_box_score('Accuracy'),\n",
    "            \"F1\": score_f1,\n",
    "            \"ΔF1\": score_f1 - out_of_the_box_score('F1'),\n",
    "            \"Train_time\": train_time,\n",
    "            \"Test_time\": test_time,\n",
    "            \"Preds\": preds\n",
    "        },\n",
    "        ignore_index=True)\n",
    "\n",
    "\n",
    "def use_cv(operations, scoring_metric, param_grid, classifier):\n",
    "    pipe = Pipeline(steps=operations, memory='tmp')\n",
    "    cv_classifier = GridSearchCV(pipe,\n",
    "                                 param_grid,\n",
    "                                 cv=10,\n",
    "                                 scoring=scoring_metric,\n",
    "                                 n_jobs=-1)\n",
    "    cv_classifier.fit(train, train_labels)\n",
    "\n",
    "    print('''Statistics for {} on {} scoring metric:\n",
    "          Best Score = {}\n",
    "          Best Estimator = {}'''.format(classifier, scoring_metric,\n",
    "                                        cv_classifier.best_score_,\n",
    "                                        cv_classifier.best_estimator_))\n",
    "    return cv_classifier\n",
    "\n",
    "\n",
    "def get_params(params_dicts, operations):\n",
    "    params_dict = {}\n",
    "    for (op_name, _) in operations:\n",
    "        if op_name in params_dicts:\n",
    "            for k, v in params_dicts[op_name].items():\n",
    "                params_dict[op_name + '__' + k] = v\n",
    "    return params_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για την βελτιστοποίηση όλων των classifier χρησιμοποιήσαμε κάθε φορά ένα dictionary, το params_dicts, στο οποίο έχουμε τα operations και τις τιμές των υπερπαραμέτρων από τα οποία αντλούμε για να αποφανθούμε ποια θα οδηγήσουν στην βελτιστοποίηση του best score στο train set. Συγκεκριμένα, σε όλες τις περιπτώσεις κοινό έχουμε τον Robust Scaler με τις υπερπαραμέτρους with_centering, with_scaling και unit_variance, τον Standard Scaler, με τις υπερπαραμέτρους with_mean και with_std και το PCA, με την υπερπαράμετρο n_components να παίρνει τιμές από μια λίστα, όπως φαίνεται παρακάτω. Τέλος, χρησιμοποιήσαμε και το Select Percentile, το οποίο κάθε φορά επιλέγει τα χαρακτηριστικά με βάση ένα ποσοστό (που παίρνει από μια λίστα που φαίνεται παρακάτω) των καλύτερων scores. Καλό θα ήταν γενικά να αναφερθεί επίσης πως δοκιμάσαμε τόσο την χρήση του Random Oversampler όσο και του Variance Threshold, αλλά κανένα από τα 2 δεν φάνηκε να βοηθάει στην βελτιστοποίηση των επιδόσεων.\n",
    "\n",
    "Παρακάτω θα δούμε αναλυτικότερα την διαδικασία που ακολουθήθηκε στην προσπάθεια βελτιστοποίησης καθενός από τους ζητούμενους classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wYgJdqq9DcU"
   },
   "source": [
    "### Dummy classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "748KonWGvMOG"
   },
   "source": [
    "Στον Dummy classifier, στο params_dicts, πέρα από τα υπόλοιπα που αναφέρθηκαν έχουμε βάλει ταυτόχρονα στον ίδιο τον classifier να επιλέγει μεταξύ 4 στρατηγικών, και παραλείψαμε την στρατηγική constant, διότι δεν θέλουμε να προβλέπει μια συγκεκριμένη ετικέτα που θα δώσουμε εμείς."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dicts = {\n",
    "    'robust_scaler': {\n",
    "        'with_centering': [True, False],\n",
    "        'with_scaling': [True, False],\n",
    "        'unit_variance': [True, False],\n",
    "    },\n",
    "    'standard_scaler': {\n",
    "        'with_mean': [True, False],\n",
    "        'with_std': [True, False]\n",
    "    },\n",
    "    'pca': {\n",
    "        'n_components': [i for i in range(10, 70, 10)]\n",
    "    },\n",
    "    'dummy': {\n",
    "        'strategy': ['stratified', 'most_frequent', 'prior', 'uniform']\n",
    "    },\n",
    "    'select_percentile': {\n",
    "        'percentile': [i for i in range(10, 110, 10)]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfaqxCdemtPe"
   },
   "source": [
    "#### Accuracy based scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Συγκεκριμένα τώρα με μετρική το accuracy, εξετάσαμε μια σειρά από περιπτώσεις και συνδυασμούς μεταξύ των προαναφερθέντων operations, με σκοπό να δούμε ποιος θα οδηγήσει σε μεγαλύτερο score. Αρχικά, δοκιμάσαμε μόνο με τον dummy operation, χωρίς να έχουμε μεγάλο score, όπως και περιμέναμε. Στην συνέχεια, με βάση τον dummy πάντα, όταν προσθέσαμε και scaler, αυξήθηκε και στους δύο scalers, αλλά με τον robust να είχε καλύτερο αποτέλεσμα. Ύστερα, αφαιρέσαμε τους scaler και βάλαμε PCA, αλλά οι επιδόσεις ουσιαστικά μειώθηκαν. Όταν στην συνέχεια βάλαμε και PCA και τους δύο scaler εναλλάξ μεταξύ τους, παρατηρήσαμε πως οι επιδόσεις γενικά αυξήθηκαν, με την μέγιστη από όλες να είναι η Standard Scaler + PCA, την οποία και τελικά χρησιμοποιήσαμε, όπως φαίνεται παρακάτω στα operations. Στο τέλος, βάλαμε και το Feature Selection επιπλεόν σε αυτά, αλλά η επίδοση έμεινε ουσιαστικά η ίδια, με ελάχιστη μείωση. Για αυτόν τον λόγο, λοιπόν, κρατάμε το Standard Scaler + PCA σαν την καλύτερη περίπτωση για τον Dummy με μετρική accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nNAyG5Eqnsu",
    "outputId": "17d2b4ca-145f-418f-c9a8-52a11161ef13"
   },
   "outputs": [],
   "source": [
    "operations = [('standard_scaler', StandardScaler()), ('pca', PCA()),\n",
    "              ('dummy', DummyClassifier())]\n",
    "\n",
    "param_grid = get_params(params_dicts, operations)\n",
    "\n",
    "dummy_acc_classifier = use_cv(operations, 'accuracy', param_grid, 'Dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tY1xnq38eYs5"
   },
   "source": [
    "#### F1 based scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Την ίδια διαδικασία ακολουθήσαμε και για την μετρική του F1. Αρχικά, δοκιμάσαμε μόνο με τον dummy operation, χωρίς να έχουμε μεγάλο score, όπως και περιμέναμε. Στην συνέχεια, με βάση τον dummy πάντα, όταν προσθέσαμε και scaler, στον Standard μειώθηκε ενώ στον Robust έμεινε περίπου ίδιο. Περίπου ίδιο παρέμεινε και όταν αφαιρέσαμε τους scaler και βάλαμε μόνο το PCA. Στην συνέχεια, όταν βάλαμε και PCA και τους δύο scaler εναλλάξ, παρατήρησαμε ότι τα αποτελέσματα ήταν ξανά περίπου ίδια, με μια μικρή αύξηση. Στο τέλος, δοκιμάζοντας τόσο τους scaler, όσο και το Feature Selection και το PCA μαζί, τότε παρατηρήσαμε ότι σημειώθηκε αύξηση, με την μεγαλύτερη να σημειώνεται στο συνδυασμό Standard Scaler + Feature Selection + PCA, τον οποίο και τελικά χρησιμοποιήσαμε. Εδώ αξίζει να σημειωθεί πως o Dummy Classifier είχε διαφορετικό συνδυασμό για βελτιστοποίηση με μετρική το accuracy, και διαφορετικό με μετρική το F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QI2EJOhteYs6",
    "outputId": "38869601-410b-4c35-f426-960630f88737"
   },
   "outputs": [],
   "source": [
    "operations = [('standard_scaler', StandardScaler()), ('select_percentile', SelectPercentile()), ('pca', PCA()),\n",
    "              ('dummy', DummyClassifier())]\n",
    "\n",
    "param_grid = get_params(params_dicts, operations)\n",
    "\n",
    "dummy_f1_classifier = use_cv(operations, 'f1', param_grid, 'Dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CkfLaGI9DcV"
   },
   "source": [
    "### Gaussian Naive Bayes (GNB) classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coCdIdQp_HUJ"
   },
   "source": [
    "Στον Gaussian Naive Bayes (GNB) classifier, στο params_dicts, πέρα από τα υπόλοιπα που αναφέρθηκαν έχουμε βάλει ταυτόχρονα στον ίδιο τον classifier την παράμετρο var_smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "162Vm0Ggqnsv"
   },
   "outputs": [],
   "source": [
    "params_dicts = {\n",
    "    'robust_scaler': {\n",
    "        'with_centering': [True, False],\n",
    "        'with_scaling': [True, False],\n",
    "        'unit_variance': [True, False],\n",
    "    },\n",
    "    'standard_scaler': {\n",
    "        'with_mean': [True, False],\n",
    "        'with_std': [True, False]\n",
    "    },\n",
    "    'pca': {\n",
    "        'n_components': [i for i in range(10, 70, 10)]\n",
    "    },\n",
    "    'select_percentile': {\n",
    "        'percentile': [i for i in range(10, 110, 10)]\n",
    "    },\n",
    "    'gnb': {\n",
    "        'var_smoothing': np.logspace(0, -9, 50)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flmcdajbmw5v"
   },
   "source": [
    "#### Accuracy based scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Την ίδια νοοτροπία ακολουθήσαμε και για τον GNB με μετρική accuracy. Αρχικά, δοκιμάσαμε μόνο με το gnb operation, χωρίς να έχουμε ιδιαίτερα μεγάλο score, όπως και περιμέναμε. Στην συνέχεια, με βάση τον gnb πάντα, όταν προσθέσαμε και scaler, δεν παρατηρήσαμε αύξηση σε κανένα από τους 2. Μεγάλη αύξηση παρατηρήσαμε όταν βγάλαμε τους scaler και βάλαμε μόνο το PCA. Στην συνέχεια, όταν μαζί με τον PCA βάλαμε και τους δύο scaler εναλλάξ, τότε παρατηρήσαμε πως υπήρχε μια μικρή βελτίωση αναλογικά με το PCA μόνο του, και για αυτό θεωρήσαμε και τον συνδυασμό Standard Scaler + PCA ως τον καλύτερο, τον οποίο και χρησιμοποιήσαμε κιόλας, όπως φαίνεται παρακάτω. Τέλος, όταν προσθέσαμε και Feature Selection μαζί με τα άλλα δύο που είχαμε πριν παρατηρούμε πως έβγαινε περίπου το ίδιο αποτέλεσμα, χωρίς ιδιαίτερη αλλαγή, οπότε και για αυτό αποφασίσαμε να χρησιμοποιήσουμε τον συνδυασμό Standard Scaler + PCA ως τον βέλτιστο."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0XUTcLvfBm7",
    "outputId": "932f7e3a-ae42-4ef5-9638-9fe07aa15824"
   },
   "outputs": [],
   "source": [
    "operations = [('standard_scaler', StandardScaler()), ('pca', PCA()), ('gnb', GaussianNB())]\n",
    "\n",
    "param_grid = get_params(params_dicts, operations)\n",
    "\n",
    "gnb_acc_classifier = use_cv(operations, 'accuracy', param_grid,\n",
    "                            'Gaussian Naive Bayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-KyTxIjepDw"
   },
   "source": [
    "#### F1 based scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Όπως και πριν, για μετρική F1 τώρα, αρχικά δοκιμάσαμε μόνο με το gnb operation, χωρίς να έχουμε ιδιαίτερα μεγάλο score, όπως και περιμέναμε. Στην συνέχεια, όταν βάλαμε τους δύο scaler εναλλάξ, παρατήρησαμε πως τα αποτελέσματα ήταν ουσιαστικά τα ίδια, με μια μικρή αύξηση. Όταν βγάλαμε τους scaler και βάλαμε το PCA μόνο του, τότε παρατηρήσαμε αύξηση περισσότερη από την αύξηση που είχαν προκαλέσει οι scaler μόνοι τους. Έτσι, όταν στην συνέχεια βάλαμε και το PCA και τους δύο scaler εναλλάξ, πήραμε την μέγιστη βελτίωση, την οποία και τελικά κρατήσαμε, στον συνδυασμό Standard Scaler + PCA. Στο τέλος, όταν βάλαμε επιπλέον και Feature Selection σε αυτά που είχαμε ήδη, τότε παρατηρήσαμε αποτέλεσμα ουσιαστικά ίδιο με το βέλτιστο, με μια μικρή μείωση, οδηγώντας μας έτσι στο συμπέρασμα πως στο GNB για την μετρική F1 ο βέλτιστος συνδυασμός είναι ο Standard Scaler + PCA, όπως ήταν και για την μετρική accuracy αντίστοιχα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FYMAfDR1epD3",
    "outputId": "43a4cf2c-71ff-4aa9-db9f-8db6a90f3c15"
   },
   "outputs": [],
   "source": [
    "operations = [('standard_scaler', StandardScaler()), ('pca', PCA()), ('gnb', GaussianNB())]\n",
    "\n",
    "param_grid = get_params(params_dicts, operations)\n",
    "\n",
    "gnb_f1_classifier = use_cv(operations, 'f1', param_grid, 'Gaussian Naive Bayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNHGXHY49DcW"
   },
   "source": [
    "### KNeirestNeighbors (kNN) classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdrtGiJcBal6"
   },
   "source": [
    "Για την βελτιστοποίηση του KNeirestNeighbors (kNN) classifier, στο params_dicts, πέρα από αυτά που έχουν αναφερθεί χρησιμοποιήσαμε στον ίδιο τον classifier σαν υπερπαραμέτρους το n_neighbors, που είναι μια λίστα από την οποία επιλέγουμε τον \"βέλτιστο\" αριθμό από τους κοντινότερους γείτονες, το weights, που είναι η συνάρτηση βάρους που χρησιμοποιείται στην πρόβλεψη, καθώς και το metric, που είναι η μετρική της απόστασης. Επίσης, στον knn τον ίδιο χρησιμοποιήσαμε και την παράμετρο n_jobs ίση με -1, έτσι ώστε να χρησιμοποιηθούν όλοι οι processors στην αναζήτηση των γειτόνων, όπως φαίνεται παρακάτω."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9cweFz1qns0"
   },
   "outputs": [],
   "source": [
    "params_dicts = {\n",
    "    'robust_scaler': {\n",
    "        'with_centering': [True, False],\n",
    "        'with_scaling': [True, False],\n",
    "        'unit_variance': [True, False],\n",
    "    },\n",
    "    'standard_scaler': {\n",
    "        'with_mean': [True, False],\n",
    "        'with_std': [True, False]\n",
    "    },\n",
    "    'pca': {\n",
    "        'n_components': [i for i in range(10, 70, 10)]\n",
    "    },\n",
    "    'select_percentile': {\n",
    "        'percentile': [i for i in range(10, 110, 10)]\n",
    "    },\n",
    "    'knn': {\n",
    "        'n_neighbors': list(range(1, 31, 2)),\n",
    "        'weights': [\"uniform\", \"distance\"],\n",
    "        'metric': [\"euclidean\", \"manhattan\", \"minkowski\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScicfmxImx7P"
   },
   "source": [
    "#### Accuracy based scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Με την ίδια λογική με πριν, για την μετρική accuracy του KNN αρχικά δοκιμάσαμε μόνο με το knn operation, στο οποίο παρατηρήσαμε γενικά μεγάλο score. Στην συνέχεια, με βάση πάντα το knn operation, όταν βάλαμε τους δύο scaler εναλλάξ, παρατηρήσαμε πως το αποτέλεσμα ήταν περίπου ίδιο, με μια μικρή αύξηση. Ύστερα, όταν βγάλαμε τους scalers και βάλαμε το PCA μόνο του παρατηρήσαμε μια μικρή μείωση. Ωστόσο, όταν μετά βάλαμε και το PCA αλλά και τους δύο scaler εναλλάξ, παρατηρήσαμε πως είχαμε αύξηση του αποτελέσματος αναλογικά με το αποτέλεσμα που έδινε το PCA μόνο του. Τέλος, όταν στον συνδυασμό αυτό προσθέσαμε και το Feature Selection, τότε παρατηρήσαμε πως η επίδοση ανέβηκε ακόμα περισσότερο από ότι πριν, με αποτέλεσμα να θεωρούμε τον συνδυασμό Standard Scaler + Feature Selection + PCA ως τον βέλτιστο για τον KNN με την μετρική accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lf-tet8Qg4wt",
    "outputId": "4a961947-3347-4c56-d293-ded9ae984256"
   },
   "outputs": [],
   "source": [
    "operations = [('standard_scaler', StandardScaler()),\n",
    "              ('select_percentile', SelectPercentile()), ('pca', PCA()),\n",
    "              ('knn', KNeighborsClassifier(n_jobs=-1))]\n",
    "\n",
    "param_grid = get_params(params_dicts, operations)\n",
    "\n",
    "knn_acc_classifier = use_cv(operations, 'accuracy', param_grid,\n",
    "                            'K-nearest neighbors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BggBBsLesxw"
   },
   "source": [
    "#### F1 based scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Όμοια με πριν, για την μετρική F1 τώρα, αρχικά δοκιμάσαμε μόνο με το knn operation, στο οποίο παρατηρήσαμε γενικά μεγάλο score. Στην συνέχεια, με βάση πάντα το knn operation, όταν βάλαμε τους δύο scaler εναλλάξ, παρατηρήσαμε πως το αποτέλεσμα ήταν περίπου ίδιο, με μια μικρή αύξηση. Ύστερα, όταν βγάλαμε τους scalers και βάλαμε το PCA μόνο του παρατηρήσαμε μια μικρή μείωση. Ωστόσο, όταν μετά βάλαμε και το PCA αλλά και τους δύο scaler εναλλάξ, παρατηρήσαμε ότι στον Standard είχαμε αποτέλεσμα καλύτερο από το αρχικό score, ενώ στον Robust είχαμε ελαφρώς μικρότερο. Τέλος, όταν στον συνδυασμό αυτό προσθέσαμε και το Feature Selection, τότε παρατηρήσαμε πως η επίδοση ανέβηκε το περισσότερο που είχε ανέβει από όλες τις περιπτώσεις, με αποτέλεσμα να θεωρούμε τον συνδυασμό Standard Scaler + Feature Selection + PCA ως τον βέλτιστο για τον KNN με την μετρική F1, όπως ακριβώς συνέβη και στην μετρική accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3-ik6YEesxx",
    "outputId": "dea2d8e6-5904-4c61-f6c0-5d891d9b7340"
   },
   "outputs": [],
   "source": [
    "operations = [('standard_scaler', StandardScaler()),\n",
    "              ('select_percentile', SelectPercentile()), ('pca', PCA()),\n",
    "              ('knn', KNeighborsClassifier(n_jobs=-1))]\n",
    "\n",
    "param_grid = get_params(params_dicts, operations)\n",
    "\n",
    "knn_f1_classifier = use_cv(operations, 'f1', param_grid, 'K-nearest neighbors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0vLb0Ub9DcX",
    "tags": []
   },
   "source": [
    "### Logistic Regression (LR) classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2grTBPxDeAb"
   },
   "source": [
    "Για την βελτιστοποίηση του Logistic Regression (LR) classifier, στο params_dict, πέρα από αυτά που αναφέρθηκαν στην αρχή, χρησιμοποιήσαμε σαν υπερπαραμέτρους του ίδιου του classifier το penalty, το οποίο παίρνει μια από τις παρακάτω 3 τιμές, το fit_intercept, για το αν μια σταθερά πρέπει να προστεθεί στην συνάρτηση απόφασης, καθώς και το C, που παίρνει τιμές από μια λίστα, όπως φαίνεται παρακάτω. Επίσης, στον ίδιο τον classifier χρησιμοποιήσαμε την παράμετρο n_jobs ίση με -1, έτσι ώστε να χρησιμοποιηθούν όλοι οι processors στην διαδικασία, καθώς και τον solver saga, όπως παρουσιάζεται παρακάτω."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jsYG7NLSqns_"
   },
   "outputs": [],
   "source": [
    "params_dicts = {\n",
    "    'robust_scaler': {\n",
    "        'with_centering': [True, False],\n",
    "        'with_scaling': [True, False],\n",
    "        'unit_variance': [True, False],\n",
    "    },\n",
    "    'standard_scaler': {\n",
    "        'with_mean': [True, False],\n",
    "        'with_std': [True, False]\n",
    "    },\n",
    "    'pca': {\n",
    "        'n_components': [i for i in range(10, 70, 10)]\n",
    "    },\n",
    "    'select_percentile': {\n",
    "        'percentile': [i for i in range(10, 110, 10)]\n",
    "    },\n",
    "    'lr': {\n",
    "        'penalty': [\"l1\", \"l2\", \"elasticnet\"],\n",
    "        'fit_intercept': [True, False],\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POlxDZtsmysO"
   },
   "source": [
    "#### Accuracy based scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αντίστοιχα με την διαδικασία που ακολουθήσαμε στις προηγούμενες περιπτώσεις, έτσι και εδώ, αρχικά δοκιμάσαμε μόνο με το lr operation, στο οποίο παρατηρήσαμε γενικά καλό score. Στην συνέχεια, με βάση πάντα το lr operation, όταν βάλαμε τους δύο scaler εναλλάξ, παρατηρήσαμε πως το αποτέλεσμα ήταν περίπου ίδιο, με μια μικρή αύξηση. Όταν στην συνέχεια αφαιρέσαμε τους scaler και βάλαμε μόνο PCA, τότε το αποτέλεσμα αυξήθηκε ακόμα περισσότερο. Ύστερα, όταν μαζί με το PCA βάλαμε εναλλάξ τους scaler, τότε παρατηρήσαμε πως το αποτέλεσμα δεν άλλαξε ιδιαίτερα. Τέλος, με την προσθήκη του Feature Selection στον παραπάνω συνδυασμό, το αποτέλεσμα έμεινε ίδιο με μια αύξηση που ουσιαστικά ήταν και η μέγιστη που παρατηρήσαμε, με αποτέλεσμα να θεωρούμε τον συνδυασμό Standard Scaler + Feature Selection + PCA ως τον βέλτιστο για το Logistic Regression με μετρική accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "R3whAqjYpT6A",
    "outputId": "ecbf4d13-7486-415b-a7b0-5e9038befec3"
   },
   "outputs": [],
   "source": [
    "operations = [('standard_scaler', StandardScaler()), ('select_percentile', SelectPercentile()), ('pca', PCA()),\n",
    "              ('lr', LogisticRegression(n_jobs=-1, solver=\"saga\"))]\n",
    "\n",
    "param_grid = get_params(params_dicts, operations)\n",
    "\n",
    "lr_acc_classifier = use_cv(operations, 'accuracy', param_grid,\n",
    "                           'Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycgSWVM4euN4",
    "tags": []
   },
   "source": [
    "#### F1 based scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αντίστοιχα με την διαδικασία που ακολουθήσαμε πριν, για το Logistic Regression με μετρική F1 αρχικά δοκιμάσαμε πάλι μόνο με το lr operation, στο οποίο παρατηρήσαμε γενικά καλό score. Στην συνέχεια, με βάση πάντα το lr operation, όταν βάλαμε τους δύο scaler εναλλάξ, παρατηρήσαμε πως το αποτέλεσμα παρουσίασε μια μικρή αύξηση. Όταν στην συνέχεια αφαιρέσαμε τους scaler και βάλαμε μόνο PCA, τότε το αποτέλεσμα αυξήθηκε ακόμα περισσότερο. Ύστερα, όταν μαζί με το PCA βάλαμε εναλλάξ τους scaler, τότε παρατηρήσαμε πως το αποτέλεσμα δεν άλλαξε ιδιαίτερα. Τέλος, με την προσθήκη του Feature Selection στον παραπάνω συνδυασμό, το αποτέλεσμα έμεινε ίδιο με μια αύξηση που ουσιαστικά ήταν και η μέγιστη που παρατηρήσαμε, με αποτέλεσμα να θεωρούμε τον συνδυασμό Standard Scaler + Feature Selection + PCA ως τον βέλτιστο για το Logistic Regression με μετρική F1, όπως ακριβώς συνέβη και στην μετρική accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "IyRxrCy4euN5",
    "outputId": "e0eed3f3-ffa0-414d-f52f-d244e85c94ac"
   },
   "outputs": [],
   "source": [
    "operations = [('standard_scaler', StandardScaler()), ('select_percentile', SelectPercentile()), ('pca', PCA()),\n",
    "              ('lr', LogisticRegression(n_jobs=-1, solver=\"saga\"))]\n",
    "\n",
    "param_grid = get_params(params_dicts, operations)\n",
    "\n",
    "lr_f1_classifier = use_cv(operations, 'f1', param_grid, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Εκπαίδευση και test βέλτιστων μοντέλων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_best_model(dummy_acc_classifier, 'Dummy', 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_best_model(dummy_f1_classifier, 'Dummy', 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_best_model(gnb_acc_classifier, 'Gaussian Naive Bayes', 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_best_model(gnb_f1_classifier, 'Gaussian Naive Bayes', 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_best_model(knn_acc_classifier, 'K-nearest neighbors', 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_best_model(knn_f1_classifier, 'K-nearest neighbors', 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_best_model(lr_acc_classifier, 'Logistic Regression', 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_best_model(lr_f1_classifier, 'Logistic Regression', 'f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljRPEnrlLYcz"
   },
   "source": [
    "## Αποτελέσματα και συμπεράσματα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xnbvVe4i9DcX",
    "outputId": "8419706c-8048-441a-82fd-6edf4245f211"
   },
   "outputs": [],
   "source": [
    "preprocessing_scores[preprocessing_scores.columns.drop('Preds')].groupby(\n",
    "    'Classifier').apply(lambda a: a.drop('Classifier', axis=1)[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "VehvUPWUXPOq"
   },
   "outputs": [],
   "source": [
    "to_plot_scores = preprocessing_scores[[\n",
    "    'Classifier', 'Scoring_metric', 'Accuracy', 'F1'\n",
    "]]\n",
    "\n",
    "to_plot_differences = preprocessing_scores[[\n",
    "    'Classifier', 'Scoring_metric', 'ΔAccuracy', 'ΔF1'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "uOwx5FxzW0pu"
   },
   "outputs": [],
   "source": [
    "migration = lambda x: {\n",
    "    'Classifier':\n",
    "        x,\n",
    "    'Scoring_metric':\n",
    "        'Out of the box',\n",
    "    'Accuracy':\n",
    "        out_of_the_box_scores.loc[\n",
    "            (out_of_the_box_scores['Classifier'] == x) &\n",
    "            (out_of_the_box_scores['Metric'] == 'Accuracy')]['Score'].values[0],\n",
    "    'F1':\n",
    "        out_of_the_box_scores.loc[\n",
    "            (out_of_the_box_scores['Classifier'] == x) &\n",
    "            (out_of_the_box_scores['Metric'] == 'F1')]['Score'].values[0],\n",
    "}\n",
    "\n",
    "old_scores = pd.DataFrame()\n",
    "for clf in np.unique(out_of_the_box_scores['Classifier']):\n",
    "    old_scores = old_scores.append(migration(clf), ignore_index=True)\n",
    "to_plot_scores = old_scores.append(to_plot_scores, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7wMtGjg4XhM5",
    "outputId": "ec4a7b7b-d582-4ac1-be8f-5ed9f418574b"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(20, 20))\n",
    "axs[0][0].get_shared_y_axes().join(axs[0][0], axs[0][1])\n",
    "axs[1][0].get_shared_y_axes().join(axs[1][0], axs[1][1])\n",
    "\n",
    "sns.barplot(\n",
    "    data=to_plot_scores,\n",
    "    y='Accuracy',\n",
    "    x='Classifier',\n",
    "    hue=\"Scoring_metric\",\n",
    "    ax=axs[0][0]).set_title(\"Accuracy of optimized and out of the box models\")\n",
    "\n",
    "sns.barplot(data=to_plot_scores,\n",
    "            y='F1',\n",
    "            x='Classifier',\n",
    "            hue=\"Scoring_metric\",\n",
    "            ax=axs[0][1]).set_title(\"F1 of optimized and out of the box models\")\n",
    "\n",
    "sns.barplot(data=to_plot_differences,\n",
    "            y='ΔAccuracy',\n",
    "            x='Classifier',\n",
    "            hue=\"Scoring_metric\",\n",
    "            palette=[\"C1\", \"C2\"],\n",
    "            ax=axs[1][0]).set_title(\n",
    "                \"Accuracy difference of optimized and out of the box models\")\n",
    "sns.barplot(data=to_plot_differences,\n",
    "            y='ΔF1',\n",
    "            x='Classifier',\n",
    "            hue=\"Scoring_metric\",\n",
    "            palette=[\"C1\", \"C2\"],\n",
    "            ax=axs[1][1]).set_title(\n",
    "                \"F1 difference of optimized and out of the box models\")\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0nwR24ddXpIM",
    "outputId": "26f4c80f-b563-4549-f8cc-80a4f7d20d4d"
   },
   "outputs": [],
   "source": [
    "without_dummy = preprocessing_scores.loc[\n",
    "    preprocessing_scores['Classifier'] != 'Dummy']\n",
    "worst_model = without_dummy[without_dummy['Accuracy'] ==\n",
    "                            without_dummy['Accuracy'].min()].iloc[0]\n",
    "best_model = without_dummy[without_dummy['Accuracy'] ==\n",
    "                           without_dummy['Accuracy'].max()].iloc[0]\n",
    "\n",
    "print('''Worst model is {} with scoring metric {} and accuracy {:.3f}\n",
    "Best model is {} with scoring metric {} and accuracy {:.3f}'''.format(\n",
    "    worst_model['Classifier'], worst_model['Scoring_metric'],\n",
    "    worst_model['Accuracy'], best_model['Classifier'],\n",
    "    best_model['Scoring_metric'], best_model['Accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "twZTd_6nXsG6"
   },
   "outputs": [],
   "source": [
    "worst_cf_matrix = confusion_matrix(worst_model['Preds'], test_labels)\n",
    "best_cf_matrix = confusion_matrix(best_model['Preds'], test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "sWSaC0ZWXsx2",
    "outputId": "13a3cb97-38e7-467b-c85a-18eaf15d3a4d"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(20, 8))\n",
    "\n",
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in worst_cf_matrix.flatten()]\n",
    "group_percentages = [\n",
    "    '{0:.2%}'.format(value)\n",
    "    for value in worst_cf_matrix.flatten() / np.sum(worst_cf_matrix)\n",
    "]\n",
    "labels = [\n",
    "    f'{v1}\\n{v2}\\n{v3}'\n",
    "    for v1, v2, v3 in zip(group_names, group_counts, group_percentages)\n",
    "]\n",
    "labels = np.asarray(labels).reshape(2, 2)\n",
    "sns.heatmap(worst_cf_matrix, annot=labels, fmt='', cmap='Blues',\n",
    "            ax=axs[0]).set_title('Worst model confussion matrix')\n",
    "\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in best_cf_matrix.flatten()]\n",
    "group_percentages = [\n",
    "    '{0:.2%}'.format(value)\n",
    "    for value in best_cf_matrix.flatten() / np.sum(best_cf_matrix)\n",
    "]\n",
    "labels = [\n",
    "    f'{v1}\\n{v2}\\n{v3}'\n",
    "    for v1, v2, v3 in zip(group_names, group_counts, group_percentages)\n",
    "]\n",
    "labels = np.asarray(labels).reshape(2, 2)\n",
    "sns.heatmap(best_cf_matrix, annot=labels, fmt='', cmap='Blues',\n",
    "            ax=axs[1]).set_title('Best model confussion matrix')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ConnectionistBench.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
